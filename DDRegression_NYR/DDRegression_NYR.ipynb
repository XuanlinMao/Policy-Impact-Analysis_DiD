{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "from typing import List\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata(\"AER20090377_FinalData.dta\")\n",
    "\n",
    "data = data[data['year'] < 2004]\n",
    "data = data[data['valid'] >= 9]\n",
    "data = data[data['month'].isin([6, 7, 8])]\n",
    "\n",
    "\n",
    "data = data[['fips', 'site_id', 'day', 'month', 'year']]\n",
    "data.drop_duplicates(inplace=True)\n",
    "data['NumDays'] = data.groupby(['fips', 'site_id', 'year'])['day'].transform('count')\n",
    "data = data[data['NumDays'] >= 69]\n",
    "data = data[['fips', 'site_id', 'year']]\n",
    "data = data.drop_duplicates()\n",
    "data = data.sort_values(by=['fips', 'site_id', 'year'])\n",
    "data.to_stata('SummerList.dta', write_index=False)\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata(\"AER20090377_FinalData.dta\")\n",
    "\n",
    "data = data[data['valid'] >= 9]\n",
    "data = data[[i for i in data.columns if '_merge' not in i]]\n",
    "data = pd.merge(data, pd.read_stata('SummerList.dta'), how='inner', on=['fips', 'site_id', 'year'])\n",
    "data.to_stata('temp.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('fips',inplace=True)\n",
    "data = pd.merge(data, pd.read_stata('AER20090377_NeighborData.dta'), on='fips', how='left', indicator=True)\n",
    "data = data[data['_merge'] == 'left_only']\n",
    "data.drop(columns=['_merge'], inplace=True)\n",
    "data.loc[data.treat_CARB!=0, 'treat_rfg'] = 0\n",
    "data.to_stata('temp.dta')\n",
    "\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Create weather variables to use in regressions---create interactions between months and weather vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata('temp.dta')\n",
    "\n",
    "# Day of week (DOW) and cross temperature effects\n",
    "data['DOW'] = pd.to_datetime(data['Date']).dt.dayofweek\n",
    "\n",
    "dow_dummies = pd.get_dummies(data['DOW'], prefix='_DM', drop_first=True)\n",
    "for col in dow_dummies.columns:\n",
    "    data[f'{col[:3]+col[4:]}'] = dow_dummies[col] * data['TempMax']\n",
    "\n",
    "dow_dummies = pd.get_dummies(data['DOW'], prefix='_Dm', drop_first=True)\n",
    "for col in dow_dummies.columns:\n",
    "    data[f'{col[:3]+col[4:]}'] = dow_dummies[col] * data['TempMin']\n",
    "\n",
    "dow_dummies = pd.get_dummies(data['DOW'], prefix='_Dr', drop_first=True)\n",
    "for col in dow_dummies.columns:\n",
    "    data[f'{col[:3]+col[4:]}'] = dow_dummies[col] * data['Rain']\n",
    "\n",
    "dow_dummies = pd.get_dummies(data['DOW'], prefix='_Ds', drop_first=True)\n",
    "for col in dow_dummies.columns:\n",
    "    data[f'{col[:3]+col[4:]}'] = dow_dummies[col] * data['Snow']\n",
    "\n",
    "# Day of Year (DOY)\n",
    "data['DOY'] = pd.to_datetime(data['Date']).dt.dayofyear\n",
    "\n",
    "# Temperature polynomials\n",
    "data['TempMax1'] = data['TempMax']\n",
    "data['TempMax2'] = data['TempMax']**2\n",
    "data['TempMax3'] = data['TempMax']**3\n",
    "data['TempMin1'] = data['TempMin']\n",
    "data['TempMin2'] = data['TempMin']**2\n",
    "data['TempMin3'] = data['TempMin']**3\n",
    "data['TempMaxMin'] = data['TempMax'] * data['TempMin']\n",
    "data['Rain1'] = data['Rain']\n",
    "data['Rain2'] = data['Rain']**2\n",
    "data['Snow1'] = data['Snow']\n",
    "data['Snow2'] = data['Snow']**2\n",
    "data['RainTempMax'] = data['Rain'] * data['TempMax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(columns=['level_0'], inplace=True)\n",
    "data = data.sort_values(by=['fips', 'site_id', 'Date'])\n",
    "\n",
    "data['TempMaxL1'] = data.groupby(['fips', 'site_id'])['TempMax'].shift(1)\n",
    "data['TempMinL1'] = data.groupby(['fips', 'site_id'])['TempMin'].shift(1)\n",
    "data['TempMaxL1'] = data['TempMaxL1'].fillna(np.nan)\n",
    "data['TempMinL1'] = data['TempMinL1'].fillna(np.nan)\n",
    "\n",
    "data['TempMaxMaxL1'] = data['TempMax'] * data['TempMaxL1']\n",
    "data['TempMaxMinL1'] = data['TempMax'] * data['TempMinL1']\n",
    "\n",
    "data['DOY'] = data['Date'].dt.dayofyear\n",
    "\n",
    "temperature_vars = [i for i in data.columns if i>=\"TempMax1\" and i <= \"TempMaxMinL1\"] \n",
    "for var in temperature_vars:\n",
    "    data[f'DOY{var}'] = data['DOY'] * data[var]\n",
    "\n",
    "data = data[data['Date'].dt.month.isin([6, 7, 8])]\n",
    "data.to_stata('temp.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Additional variables: income. Take logs of ozone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_stata('temp.dta')\n",
    "income_data = pd.read_stata('AER20090377_IncomeData.dta')\n",
    "\n",
    "temp = temp.sort_values(by=['state_code', 'county_code', 'year'])\n",
    "data = pd.merge(temp, income_data, on=['state_code', 'county_code', 'year'], how='inner', indicator=True)\n",
    "data = data[data['_merge'] == 'both']\n",
    "data = data.drop(columns=['_merge'])\n",
    "\n",
    "data = data[(data['ozone_max'] != 0) & (data['epa_8hr'] != 0)]\n",
    "\n",
    "data.dropna(subset=[i for i in data.columns if i>=\"TempMax1\" and i <= \"TempMaxMinL1\"]+['income'], inplace=True)\n",
    "\n",
    "data['lozone_max'] = np.log(data['ozone_max'])\n",
    "data['lozone_8hr'] = np.log(data['epa_8hr'])\n",
    "data.drop(columns=['treated_neighbor'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Create census region dummies and interactions. Create time trend and interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['region'] = None\n",
    "data['division'] = None\n",
    "\n",
    "region_map = {\n",
    "    1:3,\n",
    "    2:4,\n",
    "    4:4,\n",
    "    5:3,\n",
    "    6:4,\n",
    "    8:4,\n",
    "    9:1,\n",
    "    10:3,\n",
    "    11:3,\n",
    "    12:3,\n",
    "    13:3,\n",
    "    15:4,\n",
    "    16:4,\n",
    "    17:2,\n",
    "    18:2,\n",
    "    19:2,\n",
    "    20:2,\n",
    "    21:3,\n",
    "    22:3,\n",
    "    23:1,\n",
    "    24:3,\n",
    "    25:1,\n",
    "    26:2,\n",
    "    27:2,\n",
    "    28:3,\n",
    "    29:2,\n",
    "    30:4,\n",
    "    31:2,\n",
    "    32:4,\n",
    "    33:1,\n",
    "    34:1,\n",
    "    35:4,\n",
    "    36:1,\n",
    "    37:3,\n",
    "    38:2,\n",
    "    39:2,\n",
    "    40:3,\n",
    "    41:4,\n",
    "    42:1,\n",
    "    44:1,\n",
    "    45:3,\n",
    "    46:2,\n",
    "    47:3,\n",
    "    48:3,\n",
    "    49:4,\n",
    "    50:1,\n",
    "    53:4,\n",
    "    54:3,\n",
    "    55:2,\n",
    "    56:4\n",
    "}\n",
    "\n",
    "data['region'] = data['state_code'].map(region_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_dummies = pd.get_dummies(data[['year', 'region']], columns=['year', 'region'], prefix=['_RY', '_RY'], drop_first=True)\n",
    "for col in dow_dummies.columns:\n",
    "    data[f'{col[:3]+col[4:]}'] = dow_dummies[col]\n",
    "\n",
    "dow_dummies = pd.get_dummies(data[['DOW', 'region']], columns=['DOW', 'region'], prefix=['_RW', '_RW'], drop_first=True)\n",
    "for col in dow_dummies.columns:\n",
    "    data[f'{col[:3]+col[4:]}'] = dow_dummies[col]\n",
    "\n",
    "dow_dummies = pd.get_dummies(data[['region', 'DOY']], columns=['region', 'DOY'], prefix=['_RD', '_RD'], drop_first=True)\n",
    "for col in dow_dummies.columns:\n",
    "    data[f'{col[:3]+col[4:]}'] = dow_dummies[col]\n",
    "\n",
    "data['DateS'] = (data[\"Date\"] - pd.to_datetime(\"1960-01-01\")).dt.days / 365\n",
    "data['DateS2'] = data[\"DateS\"] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['RVPCty', 'RFGCty', 'CARBCty'])\n",
    "\n",
    "data['RVPCty'] = data.groupby('fips')['treat_rvpII'].transform('max')\n",
    "data['RFGCty'] = data.groupby('fips')['treat_rfg'].transform('max')\n",
    "\n",
    "data['RVPRFGCty'] = 0\n",
    "data.loc[(data['RFGCty'] == 1) & (data['RVPCty'] == 1), 'RVPRFGCty'] = 1\n",
    "data.loc[data['RVPRFGCty'] == 1, 'RFGCty'] = 0\n",
    "data.loc[data['RVPRFGCty'] == 1, 'RVPCty'] = 0\n",
    "\n",
    "data['CARBCty'] = data.groupby('fips')['treat_CARB'].transform('max')\n",
    "data['CARBRFGCty'] = 0\n",
    "data.loc[((data['RFGCty'] == 1) | (data['RVPRFGCty'] == 1)) & (data['CARBCty'] == 1), 'CARBRFGCty'] = 1\n",
    "\n",
    "data.loc[data['CARBRFGCty'] == 1, 'RFGCty'] = 0\n",
    "data.loc[data['CARBRFGCty'] == 1, 'RVPRFGCty'] = 0\n",
    "data.loc[data['CARBRFGCty'] == 1, 'CARBCty'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    col_name = f'TrendRVP{i}'\n",
    "    data[col_name] = 0\n",
    "    data.loc[(data['RVPCty'] == 1) & (data['region'] == i), col_name] = data['DateS']\n",
    "    \n",
    "    col_name = f'TrendRFG{i}'\n",
    "    data[col_name] = 0\n",
    "    data.loc[(data['RFGCty'] == 1) & (data['region'] == i), col_name] = data['DateS']\n",
    "    \n",
    "    col_name = f'TrendRVPRFG{i}'\n",
    "    data[col_name] = 0\n",
    "    data.loc[(data['RVPRFGCty'] == 1) & (data['region'] == i), col_name] = data['DateS']\n",
    "    \n",
    "    col_name = f'TrendCARB{i}'\n",
    "    data[col_name] = 0\n",
    "    data.loc[(data['CARBCty'] == 1) & (data['region'] == i), col_name] = data['DateS']\n",
    "    \n",
    "    col_name = f'TrendCARBRFG{i}'\n",
    "    data[col_name] = 0\n",
    "    data.loc[(data['CARBRFGCty'] == 1) & (data['region'] == i), col_name] = data['DateS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    data[f'QTrendRVP{i}'] = 0\n",
    "    data.loc[(data['RVPCty'] == 1) & (data['region'] == i), f'QTrendRVP{i}'] = data['DateS']**2\n",
    "\n",
    "    data[f'QTrendRFG{i}'] = 0\n",
    "    data.loc[(data['RFGCty'] == 1) & (data['region'] == i), f'QTrendRFG{i}'] = data['DateS']**2\n",
    "\n",
    "    data[f'QTrendRVPRFG{i}'] = 0\n",
    "    data.loc[(data['RVPRFGCty'] == 1) & (data['region'] == i), f'QTrendRVPRFG{i}'] = data['DateS']**2\n",
    "\n",
    "    data[f'QTrendCARB{i}'] = 0\n",
    "    data.loc[(data['CARBCty'] == 1) & (data['region'] == i), f'QTrendCARB{i}'] = data['DateS']**2\n",
    "\n",
    "    data[f'QTrendCARBRFG{i}'] = 0\n",
    "    data.loc[(data['CARBRFGCty'] == 1) & (data['region'] == i), f'QTrendCARBRFG{i}'] = data['DateS']**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by=['state_code', 'year'])\n",
    "data['StateYear'] = data.groupby(['state_code', 'year']).ngroup()\n",
    "data.drop(columns=['level_0'],inplace=True)\n",
    "data[[i for i in data.columns if i!=\"division\"]].to_stata('DD_AnalysisDataset_NYR.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "First-difference everything on panelid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata('DD_AnalysisDataset_NYR.dta')\n",
    "\n",
    "for var in ['fips', 'month', 'year', 'StateYear', 'state_code', 'EstTempFlag', 'EstTempFlagprcp']:\n",
    "    data['A_'+var] = data[var]\n",
    "\n",
    "vars_keep = [\"DateS\", \"income\", \"panelid\"]\n",
    "for start in [\"lozone_\", \"treat\", \"Temp\", \"Rain\", \"Snow\",  \"DOY\", \"Trend\", \"QTrend\",  \"_D\", \"_R\",  \"A\"]:\n",
    "    vars_keep += [col for col in data.columns if col.startswith(start)]\n",
    "\n",
    "data.sort_values(by='panelid',inplace=True)\n",
    "\n",
    "vars_to_process = [\"DateS\", \"income\"]\n",
    "for start in [\"lozone_\", \"treat\", \"Temp\", \"Rain\", \"Snow\",  \"DOY\", \"Trend\", \"QTrend\",  \"_D\", \"_R\"]:\n",
    "    vars_to_process += [col for col in data.columns if col.startswith(start)]\n",
    "\n",
    "for var in vars_to_process:\n",
    "    data[f'M{var}'] = data.groupby('panelid')[var].transform('mean')\n",
    "    data[f'{var}D'] = data[var] - data[f'M{var}']\n",
    "    data = data.drop(columns=[var, f'M{var}'])\n",
    "\n",
    "data.drop(columns=['level_0']).to_stata(\"DD_AnalysisDataset_Diffed_NYR.dta\")\n",
    "\n",
    "del(data, vars_to_process, vars_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata('DD_AnalysisDataset_Diffed_NYR.dta')\n",
    "data['incomeD'] = data['incomeD']/1000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent var: daily max ozone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genFormula(starts:List, fixed:List, y:str, nonconstant:bool = True) -> str:\n",
    "    f = \"\"\n",
    "    f += y + \" ~ \"\n",
    "    x = fixed\n",
    "    for start in starts:\n",
    "        x += [col for col in data.columns if col.startswith(start)]\n",
    "    f += ' + '.join(x)\n",
    "    if nonconstant:\n",
    "        f += \" - 1\"\n",
    "    return f\n",
    "\n",
    "def genVars(starts:List, fixed:List) -> str:\n",
    "    x = fixed\n",
    "    for start in starts:\n",
    "        x += [col for col in data.columns if col.startswith(start)]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2txt(formula, model, outdir=\"DDResults_NYR.txt\"):\n",
    "    hypos = ['treat_rvpIID = treat_rfgD', 'treat_rvpIID = treat_CARBD', 'treat_rfgD = treat_CARBD']\n",
    "    with open(outdir, \"a\") as f:\n",
    "        f.write(formula + \"\\n\\n\\n\")\n",
    "        f.write(model.summary().as_text())\n",
    "        for hypo in hypos:\n",
    "            f.write('\\n\\n\\n')\n",
    "            f.write(\"Hypothesis: \" + hypo)\n",
    "            f.write('\\n')\n",
    "            f.write(model.t_test(hypo).summary().as_text())\n",
    "        f.write(\"\\n\\n\\n\\n\" + \"#\"*80 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_all = genVars(['treat','Trend','QTrend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD', 'lozone_maxD', 'A_StateYear'])\n",
    "data = data.loc[~data[vars_all].isna().any(axis=1), vars_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = genFormula(['treat'], [], 'lozone_maxD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model)\n",
    "\n",
    "formula = genFormula(['treat','_RY'], [], 'lozone_maxD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model)\n",
    "\n",
    "formula = genFormula(['treat','_R'], [], 'lozone_maxD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model)\n",
    "\n",
    "formula = genFormula(['treat','Temp','Rain','Snow','DOY','_D','_R'], [], 'lozone_maxD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model)\n",
    "\n",
    "formula = genFormula(['treat','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_maxD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model)\n",
    "\n",
    "formula = genFormula(['treat','Trend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_maxD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model)\n",
    "\n",
    "formula = genFormula(['treat','Trend','QTrend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_maxD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent var: 8-hr ozone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_stata('DD_AnalysisDataset_Diffed_NYR.dta')\n",
    "data['incomeD'] = data['incomeD']/1000000000\n",
    "vars_all = genVars(['treat','Trend','QTrend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD', 'lozone_8hrD', 'A_StateYear'])\n",
    "data = data.loc[~data[vars_all].isna().any(axis=1), vars_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = genFormula(['treat'], [], 'lozone_8hrD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model, \"DDResults_8hr_NYR.txt\")\n",
    "\n",
    "formula = genFormula(['treat','_RY'], [], 'lozone_8hrD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model, \"DDResults_8hr_NYR.txt\")\n",
    "\n",
    "formula = genFormula(['treat','_R'], [], 'lozone_8hrD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model, \"DDResults_8hr_NYR.txt\")\n",
    "\n",
    "formula = genFormula(['treat','Temp','Rain','Snow','DOY','_D','_R'], [], 'lozone_8hrD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model, \"DDResults_8hr_NYR.txt\")\n",
    "\n",
    "formula = genFormula(['treat','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_8hrD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model, \"DDResults_8hr_NYR.txt\")\n",
    "\n",
    "formula = genFormula(['treat','Trend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_8hrD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model, \"DDResults_8hr_NYR.txt\")\n",
    "\n",
    "formula = genFormula(['treat','Trend','QTrend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_8hrD', True)\n",
    "model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "model2txt(formula, model, \"DDResults_8hr_NYR.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now DD regressions--split by urban, suburban, rural\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 4):\n",
    "    data = pd.read_stata(\"DD_AnalysisDataset_NYR.dta\")\n",
    "    data = data[data['urban'] == i]\n",
    "\n",
    "    for var in ['fips', 'month', 'year', 'StateYear', 'state_code', 'EstTempFlag', 'EstTempFlagprcp']:\n",
    "        data['A_'+var] = data[var]\n",
    "\n",
    "    vars_keep = [\"DateS\", \"income\", \"panelid\"]\n",
    "    for start in [\"lozone_\", \"treat\", \"Temp\", \"Rain\", \"Snow\",  \"DOY\", \"Trend\", \"QTrend\",  \"_D\", \"_R\",  \"A\"]:\n",
    "        vars_keep += [col for col in data.columns if col.startswith(start)]\n",
    "\n",
    "    data.sort_values(by='panelid',inplace=True)\n",
    "\n",
    "    vars_to_process = [\"DateS\", \"income\"]\n",
    "    for start in [\"lozone_\", \"treat\", \"Temp\", \"Rain\", \"Snow\",  \"DOY\", \"Trend\", \"QTrend\",  \"_D\", \"_R\"]:\n",
    "        vars_to_process += [col for col in data.columns if col.startswith(start)]\n",
    "\n",
    "    for var in vars_to_process:\n",
    "        data[f'M{var}'] = data.groupby('panelid')[var].transform('mean')\n",
    "        data[f'{var}D'] = data[var] - data[f'M{var}']\n",
    "        data = data.drop(columns=[var, f'M{var}'])\n",
    "\n",
    "    data.drop(columns=['level_0']).to_stata(f\"DD_AnalysisDataset_Diffed_NYR_{i}.dta\")\n",
    "\n",
    "del(data, vars_to_process, vars_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent var: daily max ozone. By urban/suburban/rural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 4):\n",
    "    data = pd.read_stata(f\"DD_AnalysisDataset_Diffed_NYR_{i}.dta\")\n",
    "    data['incomeD'] = data['incomeD']/1000000000\n",
    "    vars_all = genVars(['treat','Trend','QTrend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD', 'lozone_maxD', 'A_StateYear'])\n",
    "    data = data.loc[~data[vars_all].isna().any(axis=1), vars_all]\n",
    "    \n",
    "    formula = genFormula(['treat','Temp','Rain','Snow','DOY','_D','_R'], [], 'lozone_maxD', True)\n",
    "    model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "    model2txt(formula, model, f\"DDResults_NYR_{i}.txt\")\n",
    "\n",
    "    formula = genFormula(['treat','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_maxD', True)\n",
    "    model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "    model2txt(formula, model, f\"DDResults_NYR_{i}.txt\")\n",
    "\n",
    "    formula = genFormula(['treat','Trend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_maxD', True)\n",
    "    model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "    model2txt(formula, model, f\"DDResults_NYR_{i}.txt\")\n",
    "\n",
    "    formula = genFormula(['treat','Trend','QTrend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_maxD', True)\n",
    "    model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "    model2txt(formula, model, f\"DDResults_NYR_{i}.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent var: 8-hr ozone. By urban/suburban/rural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 4):\n",
    "    data = pd.read_stata(f\"DD_AnalysisDataset_Diffed_NYR_{i}.dta\")\n",
    "    data['incomeD'] = data['incomeD']/1000000000\n",
    "    vars_all = genVars(['treat','Trend','QTrend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD', 'lozone_8hrD', 'A_StateYear'])\n",
    "    data = data.loc[~data[vars_all].isna().any(axis=1), vars_all]\n",
    "    \n",
    "    formula = genFormula(['treat','Temp','Rain','Snow','DOY','_D','_R'], [], 'lozone_8hrD', True)\n",
    "    model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "    model2txt(formula, model, f\"DDResults_8hr_NYR_{i}.txt\")\n",
    "\n",
    "    formula = genFormula(['treat','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_8hrD', True)\n",
    "    model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "    model2txt(formula, model, f\"DDResults_8hr_NYR_{i}.txt\")\n",
    "\n",
    "    formula = genFormula(['treat','Trend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_8hrD', True)\n",
    "    model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "    model2txt(formula, model, f\"DDResults_8hr_NYR_{i}.txt\")\n",
    "\n",
    "    formula = genFormula(['treat','Trend','QTrend','Temp','Rain','Snow','DOY','_D','_R'], ['incomeD'], 'lozone_8hrD', True)\n",
    "    model = ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['A_StateYear']})\n",
    "    model2txt(formula, model, f\"DDResults_8hr_NYR_{i}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
